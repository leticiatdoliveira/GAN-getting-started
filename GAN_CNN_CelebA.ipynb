{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiatdoliveira/GAN-getting-started/blob/main/GAN_CNN_CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpII-qgno6EX"
      },
      "source": [
        "\n",
        "# Problem statement\n",
        "\n",
        "**Goal**: Create a convolutional GAN\n",
        "\n",
        "**Dataset**: CelebA Human Faces from torch datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "SsUKTCZYh8Tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4cVBs2wlDiv",
        "outputId": "3bc53d1a-aaa2-4378-c21f-04ea6e137c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./mount; to attempt to forcibly remount, call drive.mount(\"./mount\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./mount')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bkrfSHHAPUB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.datasets\n",
        "\n",
        "import h5py\n",
        "import pandas, numpy, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import zipfile\n",
        "import imageio\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz2Rsj32bsAA"
      },
      "source": [
        "## Standard CUDA Check And Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWcKqW6bwSS",
        "outputId": "1b856470-6343-4761-d06a-76ec2441ef18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda: Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# check if CUDA is available\n",
        "# if yes, set default tensor type to cuda\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
        "  pass\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWIiynblQJ4o"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px_g8nYPBD3A"
      },
      "outputs": [],
      "source": [
        "def generate_random_image(size):\n",
        "    random_data = torch.rand(size)\n",
        "    return random_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)\n",
        "    return random_data"
      ],
      "metadata": {
        "id": "e7chxo3iiG1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOdjz5EkROsQ"
      },
      "outputs": [],
      "source": [
        "# modified from https://github.com/pytorch/vision/issues/720\n",
        "class View(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape,\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atacm0OBJ505"
      },
      "outputs": [],
      "source": [
        "# crop (numpy array) image to given width and height\n",
        "def crop_centre(img, new_width, new_height):\n",
        "    height, width, _ = img.shape\n",
        "    startx = width//2 - new_width//2\n",
        "    starty = height//2 - new_height//2\n",
        "    return img[  starty:starty + new_height, startx:startx + new_width, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "31hOjuCmk9_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.CelebA(root='.', download=True)"
      ],
      "metadata": {
        "id": "P9yyskgDlA3M",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Images and Re-Package as HDF5"
      ],
      "metadata": {
        "id": "XkIqMtS_lJjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'dataset' is your CelebA dataset object\n",
        "# and you want to save it to 'celeba.h5' in your current directory\n",
        "\n",
        "with h5py.File('celeba.h5', 'w') as hf:\n",
        "    images = []\n",
        "    for i in range(len(dataset)):\n",
        "        image = np.array(dataset[i][0])  # Convert PIL Image to NumPy array\n",
        "        images.append(image)\n",
        "\n",
        "    hf.create_dataset('images', data=np.array(images))\n",
        "\n",
        "# Delete the original downloaded files\n",
        "!rm -rf ./celeba\n",
        "\n",
        "print(\"CelebA dataset saved as HDF5 and original files removed.\")\n"
      ],
      "metadata": {
        "id": "IY3RAg_PnEa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o91c-ALVmw0n"
      },
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS9SJ5JI5rIW"
      },
      "outputs": [],
      "source": [
        "class CelebADataset(Dataset):\n",
        "\n",
        "    def __init__(self, file):\n",
        "        self.file_object = h5py.File(file, 'r')\n",
        "        self.dataset = self.file_object['img_align_celeba']\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if (index >= len(self.dataset)):\n",
        "          raise IndexError()\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])\n",
        "        # crop to 128x128 square\n",
        "        img = crop_centre(img, 128, 128)\n",
        "        return torch.cuda.FloatTensor(img).permute(2,0,1).view(1,3,128,128) / 255.0\n",
        "\n",
        "    def plot_image(self, index):\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])\n",
        "        # crop to 128x128 square\n",
        "        img = crop_centre(img, 128, 128)\n",
        "        plt.imshow(img, interpolation='nearest')\n",
        "        pass\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset object"
      ],
      "metadata": {
        "id": "uZNsWFQ5iV4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xznLd7Cke2r"
      },
      "outputs": [],
      "source": [
        "celeba_dataset = CelebADataset('mount/My Drive/Colab Notebooks/14_gan_cnn_celeba/celeba_aligned_small.h5py')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check data contains images"
      ],
      "metadata": {
        "id": "mrEUiu4kiZ3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKMHzHy7ltUR"
      },
      "outputs": [],
      "source": [
        "celeba_dataset.plot_image(43)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ_E9wgYQybx"
      },
      "source": [
        "# Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrgKlTsRAfSk"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "\n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            # expect input of shape (1,3,128,128)\n",
        "            nn.Conv2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 3, kernel_size=8, stride=2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            View(3*10*10),\n",
        "            nn.Linear(3*10*10, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "    def train(self, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 1000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFajrD3xCgsb"
      },
      "source": [
        "# Test Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test discriminator can separate real data from random noise"
      ],
      "metadata": {
        "id": "EieZS4lWiin4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXgCZ9DiCl3A"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "D = Discriminator()\n",
        "# move model to cuda device\n",
        "D.to(device)\n",
        "\n",
        "for image_data_tensor in celeba_dataset:\n",
        "    # real data\n",
        "    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))\n",
        "    # fake data\n",
        "    D.train(generate_random_image((1,3,128,128)), torch.cuda.FloatTensor([0.0]))\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBh8AGJFDhcU"
      },
      "outputs": [],
      "source": [
        "D.plot_progress()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUMJn6efDkH5"
      },
      "outputs": [],
      "source": [
        "# manually run discriminator to check it can tell real data from fake\n",
        "\n",
        "for i in range(4):\n",
        "  image_data_tensor = celeba_dataset[random.randint(0,20000)]\n",
        "  print( D.forward( image_data_tensor ).item() )\n",
        "  pass\n",
        "\n",
        "for i in range(4):\n",
        "  print( D.forward( generate_random_image((1,3,128,128))).item() )\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsE9-KrguowG"
      },
      "source": [
        "# Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-JwJlKDh_Ej"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "\n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            # input is a 1d array\n",
        "            nn.Linear(100, 3*11*11),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # reshape to 4d\n",
        "            View((1, 3, 11, 11)),\n",
        "\n",
        "            nn.ConvTranspose2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 3, kernel_size=8, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "\n",
        "            # output should be (1,3,128,128)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "    def train(self, D, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        g_output = self.forward(inputs)\n",
        "\n",
        "        # pass onto Discriminator\n",
        "        d_output = D.forward(g_output)\n",
        "\n",
        "        # calculate error\n",
        "        loss = D.loss_function(d_output, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwjycPNXxF7G"
      },
      "source": [
        "# Test Generator Output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the generator output is of the right type and shape"
      ],
      "metadata": {
        "id": "LKddxd7GipbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84vbfjGRwodN"
      },
      "outputs": [],
      "source": [
        "G = Generator()\n",
        "# move model to cuda device\n",
        "G.to(device)\n",
        "\n",
        "output = G.forward(generate_random_seed(100))\n",
        "\n",
        "img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "\n",
        "plt.imshow(img, interpolation='none', cmap='Blues')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k9SRwIkxTLi"
      },
      "source": [
        "# Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()\n",
        "G = Generator()\n",
        "D.to(device)\n",
        "G.to(device)"
      ],
      "metadata": {
        "id": "bj3LHD7Nitxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1"
      ],
      "metadata": {
        "id": "b5Xam4Z9iwjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "radA76P9xWr1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for epoch in range(epochs):\n",
        "  print (\"epoch = \", epoch + 1)\n",
        "\n",
        "  for image_data_tensor in celeba_dataset:\n",
        "    # train discriminator on true\n",
        "    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))\n",
        "\n",
        "    # train discriminator on false\n",
        "    # use detach() so gradients in G are not calculated\n",
        "    D.train(G.forward(generate_random_seed(100)).detach(), torch.cuda.FloatTensor([0.0]))\n",
        "\n",
        "    # train generator\n",
        "    G.train(D, generate_random_seed(100), torch.cuda.FloatTensor([1.0]))\n",
        "\n",
        "    pass\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfGwR21QxYtV"
      },
      "outputs": [],
      "source": [
        "D.plot_progress()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIx0tJBixbGM"
      },
      "outputs": [],
      "source": [
        "G.plot_progress()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vddYtD84xkmI"
      },
      "source": [
        "## Run Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot several outputs from the trained generator"
      ],
      "metadata": {
        "id": "Xx38Lh3Si3u7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mePLPy3Yxj9A"
      },
      "outputs": [],
      "source": [
        "# plot a 3 column, 2 row array of generated images\n",
        "f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        output = G.forward(generate_random_seed(100))\n",
        "        img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')\n",
        "        pass\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwenX1Nqc0m4"
      },
      "source": [
        "# Memory Consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current memory allocated to tensors (in Gb)"
      ],
      "metadata": {
        "id": "jfyfhPCEi7V7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Byshag0WEduh",
        "outputId": "1c830ad3-05c5-40eb-ba76-8aa2d2d8fe1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1423473358154297"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.memory_allocated(device) / (1024*1024*1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Q_xKcrXZc3_p",
        "outputId": "74133717-5da5-4ff8-c90a-85ac412e2578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2035832405090332"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.max_memory_allocated(device) / (1024*1024*1024)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}